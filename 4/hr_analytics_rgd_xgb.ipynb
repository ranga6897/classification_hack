{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\Users\\ranga\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns',None)\n",
    "# pd.set_option('display.max_rows',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('train_LZdllcl.csv')\n",
    "data_test = pd.read_csv('test_2umaH9m.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_copy = data_train.copy(deep = True)\n",
    "data_test_copy = data_test.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda(dataset):\n",
    "    data = dataset.copy(deep = True)\n",
    "    data.previous_year_rating.fillna(3, inplace = True)   # add main\n",
    "    data.education.fillna(\"Bachelor's\" ,inplace = True)  ##add main\n",
    "    \n",
    "    data = data.drop(columns= ['employee_id','region'])   #add main\n",
    "\n",
    "    data['awards_won?'] = data['awards_won?'].astype('object')\n",
    "    data['KPIs_met >80%'] = data['KPIs_met >80%'].astype('object')\n",
    "#     data['awards_won?'] = data['awards_won?'].astype('object')\n",
    "    \n",
    "    data = pd.get_dummies(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def under_sample(X_train, y_train, random_under_sample = True,random_replacement = False ,ver = 1):\n",
    "    # X_us = pd.DataFrame(impute(X_train), columns = X_train.columns,index = X_train.index)  #smote does not accept null values, impute returns array\n",
    "    X_us = X_train\n",
    "    y_us = y_train.copy()\n",
    "\n",
    "    from imblearn.under_sampling import RandomUnderSampler,NearMiss\n",
    "    if random_under_sample:\n",
    "        us = RandomUnderSampler(random_state=0, replacement = random_replacement)\n",
    "        columns = X_us.columns\n",
    "\n",
    "        X_train_us,y_train_us=us.fit_sample(X_us, y_us)\n",
    "        X_train_us = pd.DataFrame(data=X_train_us,columns=columns ) # both index changes , i think we dont need to change index\n",
    "    \n",
    "    else:\n",
    "        us = NearMiss(version = ver)\n",
    "        columns = X_us.columns\n",
    "\n",
    "        X_train_us,y_train_us=us.fit_sample(X_us, y_us)\n",
    "        X_train_us = pd.DataFrame(data=X_train_us,columns=columns )\n",
    "        \n",
    "        \n",
    "    return X_train_us, y_train_us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier,AdaBoostClassifier\n",
    "from xgboost import XGBRFClassifier,XGBClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,roc_curve,auc,recall_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_eda = eda(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_eda.drop(columns=['is_promoted'])\n",
    "y = data_eda.is_promoted\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y, random_state = 6, train_size = .8)\n",
    "\n",
    "X_train_us, y_train = under_sample(X_train,y_train)\n",
    "X_train = np.round(X_train_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7002 3000]\n",
      " [  80  880]]\n",
      "0.719029374201788\n",
      "auc : 0.8083633273345331\n",
      "recall : 0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.70      0.82     10002\n",
      "           1       0.23      0.92      0.36       960\n",
      "\n",
      "    accuracy                           0.72     10962\n",
      "   macro avg       0.61      0.81      0.59     10962\n",
      "weighted avg       0.92      0.72      0.78     10962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model =RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,   ## add main\n",
    "                       criterion='gini', max_depth=50, max_features=20,\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=10, min_samples_split=5,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
    "                       n_jobs=-1, oob_score=False, random_state=61,\n",
    "                       verbose=0, warm_start=False)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_predict = model.predict(X_val)\n",
    "print(confusion_matrix(y_val,y_predict)) \n",
    "print(accuracy_score(y_val,y_predict))\n",
    "    \n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_predict, pos_label=None)\n",
    "print('auc :',auc(fpr, tpr))\n",
    "print('recall :', recall_score(y_val, y_predict))\n",
    "print(classification_report(y_val, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7161 2841]\n",
      " [  97  863]]\n",
      "0.7319832147418355\n",
      "auc : 0.8074575709858028\n",
      "recall : 0.8989583333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.72      0.83     10002\n",
      "           1       0.23      0.90      0.37       960\n",
      "\n",
      "    accuracy                           0.73     10962\n",
      "   macro avg       0.61      0.81      0.60     10962\n",
      "weighted avg       0.92      0.73      0.79     10962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model =ExtraTreesClassifier(n_estimators=200, criterion='gini', max_depth=40,\n",
    "                            min_samples_split=5, min_samples_leaf=5, min_weight_fraction_leaf=0.0,  ## add main\n",
    "                            max_features=20, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                            min_impurity_split=None, bootstrap=False, oob_score=False, n_jobs=-1,\n",
    "                            random_state=None, verbose=0, warm_start=False, class_weight=None, \n",
    "                            ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_predict = model.predict(X_val)\n",
    "print(confusion_matrix(y_val,y_predict)) \n",
    "print(accuracy_score(y_val,y_predict))\n",
    "    \n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_predict, pos_label=None)\n",
    "print('auc :',auc(fpr, tpr))\n",
    "print('recall :', recall_score(y_val, y_predict))\n",
    "print(classification_report(y_val, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7112 2890]\n",
      " [  74  886]]\n",
      "0.7296113847837986\n",
      "auc : 0.816987227554489\n",
      "recall : 0.9229166666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.71      0.83     10002\n",
      "           1       0.23      0.92      0.37       960\n",
      "\n",
      "    accuracy                           0.73     10962\n",
      "   macro avg       0.61      0.82      0.60     10962\n",
      "weighted avg       0.92      0.73      0.79     10962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model =XGBClassifier(base_score=0.3, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.9, gamma=0.5,                           ## add main\n",
    "              learning_rate=.1, max_delta_step=0, max_depth=5,\n",
    "              min_child_weight=2, missing=None, n_estimators=100, n_jobs=-1,\n",
    "              nthread=None, objective='binary:logistic', random_state=61,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "              silent=None, subsample=0.7, verbosity=0)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_predict = model.predict(X_val)\n",
    "print(confusion_matrix(y_val,y_predict)) \n",
    "print(accuracy_score(y_val,y_predict))\n",
    "    \n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_predict, pos_label=None)\n",
    "print('auc :',auc(fpr, tpr))\n",
    "print('recall :', recall_score(y_val, y_predict))\n",
    "print(classification_report(y_val, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = eda(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_copy['is_promoted'] = test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_copy[['employee_id','is_promoted']].to_csv('rgd_xgb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
